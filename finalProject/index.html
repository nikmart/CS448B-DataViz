<!DOCTYPE html>
<meta charset="utf-8">


<style>
body {
  font-family: Helvetica, Arial, sans-serif;
}
.reference-line {
  stroke: #333;
  shape-rendering: crispEdges;
  stroke-dasharray: 3;
}
.connection-line {
  stroke: red;
  stroke-width: 0.5;
}
text {
  font-size: 9px;
  text-anchor: middle;
}

.axis path,
.axis line {
  fill: none;
  stroke: #000;
  shape-rendering: crispEdges;
}

.x.axis path {
  display: none;
}

.line {
  fill: none;
  stroke: steelblue;
  stroke-width: 1.5px;
}

.dot {
  fill: red;
  opacity: 0.2;
}
</style>



<body>
  <div id="player"></div>
  <br>
  <span id="qLabel"> Question: </span>
  <span id="question"> A question </span>
  <br>
<script src="http://d3js.org/d3.v3.min.js"></script>
<script type="text/javascript">

      // 2. This code loads the IFrame Player API code asynchronously.
      var tag = document.createElement('script');

      tag.src = "https://www.youtube.com/iframe_api";
      var firstScriptTag = document.getElementsByTagName('script')[0];
      firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

      // 3. This function creates an <iframe> (and YouTube player)
      //    after the API code downloads.
      var player;
      function onYouTubeIframeAPIReady() {
        player = new YT.Player('player', {
          height: '390',
          width: '640',
          videoId: '-mJIitmwd4U',
          events: {
            'onReady': onPlayerReady,
            'onStateChange': onPlayerStateChange
          }
        });
      }

      // 4. The API will call this function when the video player is ready.
      function onPlayerReady(event) {
        event.target.playVideo();
      }

      // 5. The API calls this function when the player's state changes.
      //    The function indicates that when playing a video (state=1),
      //    the player should play for six seconds and then stop.
      var done = false;
      function onPlayerStateChange(event) {
        if (event.data == YT.PlayerState.PLAYING && !done) {
          setTimeout(stopVideo, 6000);
          setTimeout(printTime, 500);
          done = true;
        }
      }

      function stopVideo() {
        player.stopVideo();
      }

      function printTime() {
        console.log(player.getCurrentTime());
      }



var margin = {top: 20, right: 20, bottom: 30, left: 50},
    width = 960 - margin.left - margin.right,
    height = 200 - margin.top - margin.bottom,
    speechheight = 100 - margin.top - margin.bottom;

var formatTime = d3.time.format("%Y-%m-%d %H:%M:%S,%L"); //[4]

var x = d3.time.scale()
    .range([0, width]);

var y = d3.scale.linear()
    .range([height, 0]);

var xAxis = d3.svg.axis()
    .scale(x)
    .orient("bottom");

var yAxis = d3.svg.axis()
    .scale(y)
    .orient("left");

var line = d3.svg.line()
    .x(function(d) { return x(d.time); })
    .y(function(d) { return y(d.speed); });

var svg = d3.select("body").append("svg")
    .attr("width", width + margin.left + margin.right)
    .attr("height", height + margin.top + margin.bottom)
  .append("g")
    .attr("transform", "translate(" + margin.left + "," + margin.top + ")");

var speechsvg = d3.select("body").append("svg")
    .attr("width", width + margin.left + margin.right)
    .attr("height", speechheight + margin.top + margin.bottom)
  .append("g")
    .attr("transform", "translate(" + margin.left + "," + margin.top + ")");

var warpspeechsvg = d3.select("body").append("svg")
    .attr("width", width + margin.left + margin.right)
    .attr("height", speechheight + margin.top + margin.bottom)
  .append("g")
    .attr("transform", "translate(" + margin.left + "," + margin.top + ")");

var equalspacespeechsvg = d3.select("body").append("svg")
    .attr("width", width + margin.left + margin.right)
    .attr("height", speechheight + margin.top + margin.bottom)
  .append("g")
    .attr("transform", "translate(" + margin.left + "," + margin.top + ")");

var speedData;
var startTime;

// load the speed data [1] for a line graph [2]
d3.tsv("/data/P3D3_speed.tsv", type, function(error, data){
  if (error) return console.warn(error);

  speedData = data;
  startTime = data[0].time;
  console.log("Start Time: ",startTime);
  x.domain(d3.extent(data, function(d) {return d.time; }));
  y.domain(d3.extent(data, function(d) {return d.speed; }))

  svg.append("g")
    .attr("class", "x axis")
    .attr("transform", "translate(0," + height + ")")
    .call(xAxis);

  svg.append("g")
    .attr("class", "y axis")
      .call(yAxis)
    .append("text")
      .attr("transform", "rotate(-90)")
      .attr("y", 6)
      .attr("dy", ".71em")
      .style("text-anchor", "end")
      .text("Speed (mph)");

  svg.append("path")
      .datum(data)
      .attr("class", "line")
      .attr("d", line);
});

function type(d) {
  d.time = formatTime.parse(d.time);
  d.speed = +d.speed;
  return d;
}

var speechData;
// create 1-D scatterplot for speech data [3]
d3.tsv("/data/P3D3_speech.tsv", typeSpeech, function(error, data){
  if (error) return console.warn(error);

  speechData = data;

  //x.domain(d3.extent(data, function(d) { return d.time; }));
  y.domain([0,1]);
  speechsvg.append("g")
      .attr("class", "x axis")
      .attr("transform", "translate(0," + speechheight + ")")
      .call(xAxis)

  speechsvg.selectAll(".dot")
      .data(data)
    .enter().append("circle")
      .attr("class", "dot")
      .attr("r", 3.5)
      .attr("cx", function(d) { return x(d.time); })
      .attr("cy", speechheight/2)
      .on("click", function(d) {
        videoTime = (d.time - startTime)/1000;
        console.log(videoTime);
        player.seekTo(videoTime); //go to the time in the video

        // print the questiosn on the screen
        span = document.getElementById("question");
        txt = document.createTextNode(d.speech);
        span.innerText = txt.textContent;
      });

    // Polylinear time scale
    var n = 3,
        factor = 10,
        zoomStart = data[4].time; //sample start point
        start = data[0].time;
        end = d3.extent(data, function(d) { return d.time; })[1];

    // Use the extended linear scale to determine the correct range values for the polylinear scale
    var polylinearTimeScale = d3.time.scale()
      .domain([start, zoomStart, d3.time.minute.offset(zoomStart, n), end])
      .range([0, 50, 200, width]);

    var warpaxis = d3.svg.axis()
      .scale(polylinearTimeScale)
      .orient("bottom");

    warpspeechsvg.append("g")
        .attr("class", "x axis")
        .attr("transform", "translate(0," + speechheight + ")")
        .call(warpaxis);

    warpspeechsvg.selectAll(".dot")
        .data(data)
      .enter().append("circle")
        .attr("class", "dot")
        .attr("r", 3.5)
        .attr("cx", function(d) { return polylinearTimeScale(d.time); })
        .attr("cy", speechheight/2)
        .on("click", function(d) {
          videoTime = (d.time - startTime)/1000;
          console.log(videoTime);
          player.seekTo(videoTime); //go to the time in the video

          // print the questiosn on the screen
          span = document.getElementById("question");
          txt = document.createTextNode(d.speech);
          span.innerText = txt.textContent;
        });

     drawEqualSpace(speechData);
});

function typeSpeech(d) {
  d.time = formatTime.parse(d.time);
  d.speech = d.speech;
  return d;
}

function drawEqualSpace (data) {

  numpts = data.length;
  console.log(numpts);

  step = width/numpts;
  console.log(step);

  equalscale = d3.range(0,width,step); //[5]
  console.log(equalscale[equalscale.length-1]);

  console.log(data);
  timedata = [];

  data.forEach(function (d) {
    timedata.push(d.time);
  });

  console.log(timedata);


  // Polylinear time scale
  // Use the extended linear scale to determine the correct range values for the polylinear scale
  var polylinearTimeScale = d3.time.scale()
    .domain(timedata)
    .range(equalscale);

  var warpaxis = d3.svg.axis()
    .scale(polylinearTimeScale)
    .orient("bottom");

  equalspacespeechsvg.append("g")
      .attr("class", "x axis")
      .attr("transform", "translate(0," + speechheight + ")")
      .call(warpaxis);

  equalspacespeechsvg.selectAll(".dot")
      .data(data)
    .enter().append("circle")
      .attr("class", "dot")
      .attr("r", 3.5)
      .attr("cx", function(d) { return polylinearTimeScale(d.time); })
      .attr("cy", speechheight/2)
      .on("click", function(d) {
        videoTime = (d.time - startTime)/1000;
        console.log(videoTime);
        player.seekTo(videoTime); //go to the time in the video

        // print the questiosn on the screen
        span = document.getElementById("question");
        txt = document.createTextNode(d.speech);
        span.innerText = txt.textContent;
      });
}


// References
// [1] Loading JSON data: https://github.com/d3/d3/wiki/Requests
// [2] Line graph: https://bl.ocks.org/mbostock/3883245
// [3] Scatterplot: http://bl.ocks.org/mbostock/3887118
// [4] Time formatting: https://github.com/d3/d3/wiki/Time-Formatting
// [5] Arrays in d3, creating arrays
</script>
